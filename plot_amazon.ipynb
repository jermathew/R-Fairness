{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHOOSE THE ATTRIBUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = \"sentiment\"\n",
    "#attr = \"gender\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fairness_all_functions import * \n",
    "import random\n",
    "from ast import literal_eval\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df_reviews = pd.read_csv(\"dataset/amazon_reviews.csv\")\n",
    "\n",
    "list_items = list(set(df_reviews[\"item_id\"].tolist()))\n",
    "num_items = len(list_items)\n",
    "print(list_items)\n",
    "print(num_items)\n",
    "\n",
    "#df_reviews['ethnicity'] = df_reviews['ethnicity'].astype(str)\n",
    "#df_reviews['age'] = df_reviews['age'].fillna(-1).astype(int)\n",
    "\n",
    "df_reviews['sentiment'] = df_reviews['sentiment'].astype(str)\n",
    "df_reviews['rating'] = df_reviews['rating'].apply(lambda x: 5 if x > 5.1 else x)\n",
    "df_reviews['rating'] = df_reviews['rating'].fillna(1).astype(int)\n",
    "df_reviews['rating'] = df_reviews['rating'].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "# Add utility column with 0 as minimum\n",
    "\n",
    "df_reviews['utility'] = None \n",
    "for i in range(len(df_reviews)):\n",
    "    utility_i = eval(df_reviews.iloc[i][\"counts\"])[\"useful\"]\n",
    "    df_reviews.loc[i,\"utility\"] = utility_i + 1\n",
    "\n",
    "\n",
    "def parse_into_dataframe(text_filepath: Path):\n",
    "\n",
    "    with open(text_filepath, 'r') as file:\n",
    "        data = file.read()\n",
    "\n",
    "    data = data.split('\\n')\n",
    "    \n",
    "    parsed_data = []\n",
    "    for line in tqdm(data):\n",
    "        if line:\n",
    "            parsed_data.append(literal_eval(line))\n",
    "    \n",
    "    # create a dataframe\n",
    "    df = pd.DataFrame(parsed_data, columns=column_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add gender to reviews\n",
    "df_user = pd.read_csv(\"dataset/amazon_user_demographics.csv\")\n",
    "df_user[[\"user_id\",\"gender\"]]\n",
    "dict_users = df_user.set_index('user_id').to_dict()['gender']\n",
    "df_reviews['gender'] = df_reviews['user_id'].map(dict_users)\n",
    "df_reviews['gender'] = df_reviews['gender'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add +1 in order to avoid 0 utility\n",
    "df_reviews['utility'] = np.log2(df_reviews['utility'].astype(float)) +1\n",
    "#df_reviews.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dict = {\n",
    "    'positive': 'pos',\n",
    "    'negative': 'neg',\n",
    "    'neutral': 'neu'\n",
    "}\n",
    "\n",
    "df_reviews['sentiment'] = df_reviews['sentiment'].map(sentiment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = df_reviews.drop(columns=['date', 'text', 'country', 'counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews.to_csv('dataset/amazon_review_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_reviews is the number of reviews per object\n",
    "number_reviews = 10000\n",
    "number_kendall = 10 # BETTER 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if attr == \"sentiment\":\n",
    "    list_attr = list(set(df_reviews['sentiment']))\n",
    "    list_attr = [\"pos\", \"neg\", \"neu\"]\n",
    "    list_symbols = [\"pos\", \"neg\", \"neu\"]\n",
    "    column_str = 'sentiment'\n",
    "\n",
    "if attr == \"gender\":\n",
    "    list_attr = list(set(df_reviews['gender']))\n",
    "    list_attr = [\"nan\", \"female\", \"male\", \"andy\"]\n",
    "    list_symbols = [\"nan\", \"female\", \"male\", \"andy\"]\n",
    "    column_str = 'gender'\n",
    "\n",
    "column_names = list_attr\n",
    "num_attr = len(list_attr)\n",
    "print(list_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REMOVE NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_attr = [s for s in list_attr if s != \"nan\"]\n",
    "list_symbols = [s for s in list_symbols if s != \"nan\"]\n",
    "column_names = list_attr\n",
    "num_attr = len(list_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every value in list_attr, count the molteplicity for each item\n",
    "\n",
    "attr_dict = {key: None for key in list_attr}\n",
    "\n",
    "for attr_i in list_attr:\n",
    "    multiplicity_i = 0\n",
    "    for item in list_items:\n",
    "        x = (df_reviews[column_str][df_reviews[\"item_id\"] == item].head(50)).tolist()\n",
    "        multiplicity = Counter(x)\n",
    "        #print(multiplicity)\n",
    "        multiplicity_i += multiplicity[attr_i]\n",
    "\n",
    "    attr_dict[attr_i] = multiplicity_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_dict_values_by_sum(d):\n",
    "    # Calculate the sum of all values in the dictionary\n",
    "    total_sum = sum(d.values())\n",
    "\n",
    "        \n",
    "    # Divide each value in the dictionary by the total sum\n",
    "    result_dict = {key: round((value / total_sum),4) for key, value in d.items()}\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "# Divide all values of the dictionary by the sum of all values\n",
    "frequencies = divide_dict_values_by_sum(attr_dict)\n",
    "\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONE LEVEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists_items_exp_avg = list()\n",
    "list_of_lists_items_exp_top = list()\n",
    "#list_of_lists_items_treatment_avg = list()\n",
    "list_of_lists_items_treatment_top = list()\n",
    "list_of_lists_items_kendall = list()\n",
    "for i in range(num_items):\n",
    "        list_of_lists_items_exp_avg.append(list())\n",
    "        list_of_lists_items_exp_top.append(list())\n",
    "        #list_of_lists_items_treatment_avg.append(list())\n",
    "        list_of_lists_items_treatment_top.append(list())\n",
    "        list_of_lists_items_kendall.append(list())\n",
    "\n",
    "for i in range(num_items):\n",
    "        #print(i)\n",
    "        item_i = list_items[i]\n",
    "        df_reviews_i = df_reviews[df_reviews[\"item_id\"] == item_i].head(number_reviews)\n",
    "        df_reviews_i_kendall = df_reviews[df_reviews[\"item_id\"] == item_i].head(number_kendall)\n",
    "\n",
    "        list_df_attr_i = []\n",
    "        list_df_attr_i_kendall = []\n",
    "        for j in range(num_attr):\n",
    "                list_df_attr_i.append(df_reviews_i[df_reviews_i[column_str] == list_attr[j]]) \n",
    "                list_df_attr_i_kendall.append(df_reviews_i_kendall[df_reviews_i_kendall[column_str] == list_attr[j]])\n",
    "\n",
    "\n",
    "\n",
    "        for j in range(num_attr):\n",
    "                if len(list_df_attr_i[j]) > 0:\n",
    "                        list_of_lists_items_exp_avg[i].append(exposure_avg(list_df_attr_i[j]))\n",
    "                        list_of_lists_items_exp_top[i].append(exposure_top(list_df_attr_i[j]))\n",
    "                        #list_of_lists_items_treatment_avg[i].append(treatment_avg(list_df_attr_i[j]))\n",
    "                        list_of_lists_items_treatment_top[i].append(treatment_top(list_df_attr_i[j]))\n",
    "                else:\n",
    "                        #print(\"NULL CASE\", list_attr[j])\n",
    "                        list_of_lists_items_exp_avg[i].append(0)\n",
    "                        list_of_lists_items_exp_top[i].append(0)\n",
    "                        #list_of_lists_items_treatment_avg[i].append(0)\n",
    "                        list_of_lists_items_treatment_top[i].append(0)\n",
    "\n",
    "\n",
    "                if len(list_df_attr_i_kendall[j]) > 0:\n",
    "                        # KENDALL CASE: I NEED DF DIFFERENCE\n",
    "                        merged_df = df_reviews_i_kendall.merge(list_df_attr_i_kendall[j], how='left', indicator=True)\n",
    "                        difference_df = merged_df[merged_df['_merge'] == 'left_only'].drop(columns='_merge')\n",
    "\n",
    "                        if (len(difference_df) != 0):\n",
    "                                list_of_lists_items_kendall[i].append(kendall_tau_asymmetric(list_df_attr_i_kendall[j], difference_df))\n",
    "                else:\n",
    "                        list_of_lists_items_kendall[i].append(-2)\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_boxplot/one_level/list_of_lists_items_exp_avg.txt', 'w') as file:\n",
    "    for sublist in list_of_lists_items_exp_avg:\n",
    "        file.write('[' + ', '.join(map(str, sublist)) + ']\\n')\n",
    "\n",
    "with open('data_boxplot/one_level/list_of_lists_items_exp_top.txt', 'w') as file:\n",
    "    for sublist in list_of_lists_items_exp_top:\n",
    "        file.write('[' + ', '.join(map(str, sublist)) + ']\\n')\n",
    "\n",
    "#with open('data_boxplot/one_level/list_of_lists_items_treatment_avg.txt', 'w') as file:\n",
    "#    for sublist in list_of_lists_items_treatment_avg:\n",
    "#        file.write('[' + ', '.join(map(str, sublist)) + ']\\n')\n",
    "\n",
    "with open('data_boxplot/one_level/list_of_lists_items_treatment_top.txt', 'w') as file:\n",
    "    for sublist in list_of_lists_items_treatment_top:\n",
    "        file.write('[' + ', '.join(map(str, sublist)) + ']\\n')\n",
    "\n",
    "with open('data_boxplot/one_level/list_of_lists_items_kendall.txt', 'w') as file:\n",
    "    for sublist in list_of_lists_items_kendall:\n",
    "        file.write('[' + ', '.join(map(str, sublist)) + ']\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirpath = Path.cwd()/ 'data_boxplot/one_level'\n",
    "# list the text files in the data directory\n",
    "text_files = list(data_dirpath.glob('*.txt'))\n",
    "\n",
    "# iterate through the text files and parse the data\n",
    "fairness_measure_to_df = {}\n",
    "for filepath in text_files:\n",
    "    filename = filepath.stem\n",
    "    filename = filename.split('_')\n",
    "    fairness_measure_name = filename[-2:]\n",
    "    fairness_measure_name = '_'.join(fairness_measure_name)\n",
    "    fairness_measure_to_df[fairness_measure_name] = parse_into_dataframe(filepath)\n",
    "\n",
    "# replace every -2 with NaN for the item_kendall fairness measure and\n",
    "# every 0 with NaN for the other fairness measures\n",
    "for fairness_measure, df in fairness_measure_to_df.items():\n",
    "    if fairness_measure == 'items_kendall':\n",
    "        fairness_measure_to_df[fairness_measure] = df.replace(-2, pd.NA)\n",
    "    else:\n",
    "        fairness_measure_to_df[fairness_measure] = df.replace(0, pd.NA)\n",
    "\n",
    "# generate a boxplot for each fairness measure\n",
    "# and save the plot as an html file\n",
    "for fairness_measure, df in fairness_measure_to_df.items():\n",
    "    print(fairness_measure)\n",
    "    fig = go.Figure()\n",
    "    for column in df.columns:\n",
    "        fig.add_trace(go.Box(y=df[column], name=column))\n",
    "    \n",
    "    if fairness_measure == 'items_kendall':\n",
    "        fig.update_layout(yaxis_range=[-1.1, 1.1])\n",
    "        #fig.update_layout(title = fairness_measure)\n",
    "    else:\n",
    "        fig.update_layout(yaxis_range=[-0.1, 1.1])\n",
    "        #fig.update_layout(title =  str(fairness_measure)+str(\" for \") + str(column_str) + str(\" with first \")+ str(number_reviews)+ \" reviews\")\n",
    "\n",
    "    \n",
    "    fig.update_layout(showlegend=False, width=300, height=250)\n",
    "    #fig.update_layout(title = fairness_measure)\n",
    "\n",
    "    # Define the custom labels you want to use\n",
    "    fig.update_xaxes(tickvals=list_attr, ticktext=list_symbols)\n",
    "\n",
    "    #if fairness_measure == 'items_kendall':\n",
    "    #    fig.update_layout(annotations=[dict(x=-0.12, y=0.5, text=\"rank_equality\", showarrow=False, textangle=-90, \n",
    "    #                      xref=\"paper\", yref=\"paper\", font=dict(size=14))])      \n",
    "    #else:\n",
    "    #    fig.update_layout(annotations=[dict(x=-0.12, y=0.5, text=fairness_measure, showarrow=False, textangle=-90, \n",
    "    #                      xref=\"paper\", yref=\"paper\", font=dict(size=14))])\n",
    "    fig.update_layout(margin=dict(l=5, r=5, t=5, b=0))\n",
    "    \n",
    "    fig.write_image(\"data_boxplot/plot/one_level/\"+str(fairness_measure)+\".png\")\n",
    "    fig.show()\n",
    "\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
