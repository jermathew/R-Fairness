{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHOOSE THE ATTRIBUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attr = \"age\"\n",
    "attr = \"star\"\n",
    "#attr = \"eth\"\n",
    "#attr = \"gender\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fairness_all_functions import * \n",
    "import random\n",
    "from ast import literal_eval\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df_reviews = pd.read_csv(\"dataset/yelp_reviews.csv\")\n",
    "df_items = pd.read_csv(\"dataset/yelp_items_with_rating.csv\")\n",
    "\n",
    "list_items = df_items[\"item_id\"].tolist()\n",
    "num_items = len(list_items)\n",
    "print(num_items)\n",
    "\n",
    "df_reviews['ethnicity'] = df_reviews['ethnicity'].astype(str)\n",
    "df_reviews['age'] = df_reviews['age'].fillna(-1).astype(int)\n",
    "\n",
    "\n",
    "# Add utility column with 0 as minimum\n",
    "\n",
    "df_reviews['utility'] = None \n",
    "for i in range(len(df_reviews)):\n",
    "    utility_i = eval(df_reviews.iloc[i].feedback)[\"counts\"][\"useful\"]\n",
    "    df_reviews.loc[i,\"utility\"] = utility_i +1\n",
    "\n",
    "# Function to map age to age group\n",
    "def age_to_group(age):\n",
    "    if age < 0:\n",
    "        return 'nan'\n",
    "    elif age <= 25:\n",
    "        return '0-25'\n",
    "    elif age <= 45:\n",
    "        return '26-45'\n",
    "    elif age <= 65:\n",
    "        return '46-65'\n",
    "    else:\n",
    "        return 'over 65'\n",
    "\n",
    "# Apply the function to the 'age' column\n",
    "df_reviews['age_group'] = df_reviews['age'].apply(age_to_group)\n",
    "\n",
    "# utility function to parse Lorenzo's data (funzione di Jerin!)\n",
    "def parse_into_dataframe(text_filepath: Path):\n",
    "\n",
    "    with open(text_filepath, 'r') as file:\n",
    "        data = file.read()\n",
    "\n",
    "    data = data.split('\\n')\n",
    "    \n",
    "    parsed_data = []\n",
    "    for line in tqdm(data):\n",
    "        if line:\n",
    "            parsed_data.append(literal_eval(line))\n",
    "    \n",
    "    # create a dataframe\n",
    "    df = pd.DataFrame(parsed_data, columns=column_names)\n",
    "    return df\n",
    "\n",
    "df_reviews['gender'] = df_reviews['gender'].astype(str)\n",
    "#df_reviews[\"gender\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_reviews is the number of reviews per restaurant\n",
    "number_reviews = 10000\n",
    "number_kendall = 10 # BETTER 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if attr == \"age\":\n",
    "    list_attr = list(set(df_reviews['age_group']))\n",
    "    list_attr = ['nan','26-45','0-25','46-65','over 65']\n",
    "    list_symbols = ['nan','26-45','0-25','46-65','over 65']\n",
    "    column_str = 'age_group'\n",
    "\n",
    "if attr == \"gender\":\n",
    "    list_attr = list(set(df_reviews['age_group']))\n",
    "    list_attr = ['nan','feminine','masculine']\n",
    "    list_symbols = ['nan','feminine','masculine']\n",
    "    column_str = 'gender'\n",
    "\n",
    "if attr == \"star\":\n",
    "    list_attr = list(set(df_reviews['rating']))\n",
    "    list_attr = [5,4,3,2,1]\n",
    "    list_symbols =['5','4','3','2','1']\n",
    "    column_str = 'rating'\n",
    "if attr == \"eth\":\n",
    "    list_attr = list(set(df_reviews['ethnicity']))\n",
    "    #list_attr.remove('american indian or alaska native')\n",
    "    list_attr = ['nan', 'white', 'asian', 'hispanic, latino, or spanish origin', 'black or african american', 'middle eastern or north african', \n",
    "            'native hawaiian or pacific islander', 'american indian or alaska native']\n",
    "    list_symbols = ['nan','wh','as','hi','bl','mi','ha','am']\n",
    "    column_str = 'ethnicity'\n",
    "\n",
    "column_names = list_attr\n",
    "num_attr = len(list_attr)\n",
    "print(list_attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REMOVE NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_attr = [s for s in list_attr if s != \"nan\"]\n",
    "list_symbols = [s for s in list_symbols if s != \"nan\"]\n",
    "column_names = list_attr\n",
    "num_attr = len(list_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every value in list_attr, count the molteplicity for each item\n",
    "\n",
    "attr_dict = {key: None for key in list_attr}\n",
    "\n",
    "for attr_i in list_attr:\n",
    "    multiplicity_i = 0\n",
    "    for item in list_items:\n",
    "        x = (df_reviews[column_str][df_reviews[\"item_id\"] == item].head(number_reviews)).tolist()\n",
    "        multiplicity = Counter(x)\n",
    "        #print(multiplicity)\n",
    "        multiplicity_i += multiplicity[attr_i]\n",
    "\n",
    "    attr_dict[attr_i] = multiplicity_i\n",
    "\n",
    "attr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_dict_values_by_sum(d):\n",
    "    # Calculate the sum of all values in the dictionary\n",
    "    total_sum = sum(d.values())\n",
    "        \n",
    "    # Divide each value in the dictionary by the total sum\n",
    "    result_dict = {key: round((value / total_sum),4) for key, value in d.items()}\n",
    "    \n",
    "    return result_dict\n",
    "\n",
    "# Divide all values of the dictionary by the sum of all values\n",
    "frequencies = divide_dict_values_by_sum(attr_dict)\n",
    "\n",
    "print(frequencies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new_frequencies is used to replace \"nan\" values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    new_frequencies = {key: None for key in frequencies.keys()}\n",
    "    new_frequencies[\"nan\"] = 0\n",
    "    for key in frequencies.keys():\n",
    "        if key != \"nan\":\n",
    "            print(key)\n",
    "            new_frequencies[key] = frequencies[key]/(1-frequencies[\"nan\"])\n",
    "\n",
    "    print(new_frequencies)\n",
    "\n",
    "    # Extract keys and probabilities\n",
    "    keys = list(new_frequencies.keys())\n",
    "    weights = list(new_frequencies.values())\n",
    "\n",
    "    for index, row in df_reviews.iterrows():\n",
    "        if row[\"ethnicity\"] == \"nan\":\n",
    "            x = random.choices(keys, weights=weights)[0]\n",
    "            df_reviews.at[index,\"ethnicity\"] = x\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONE LEVEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take only the first 50 for each item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists_items_exp_avg = list()\n",
    "list_of_lists_items_exp_top = list()\n",
    "#list_of_lists_items_treatment_avg = list()\n",
    "list_of_lists_items_treatment_top = list()\n",
    "list_of_lists_items_kendall = list()\n",
    "for i in range(num_items):\n",
    "        list_of_lists_items_exp_avg.append(list())\n",
    "        list_of_lists_items_exp_top.append(list())\n",
    "        #list_of_lists_items_treatment_avg.append(list())\n",
    "        list_of_lists_items_treatment_top.append(list())\n",
    "        list_of_lists_items_kendall.append(list())\n",
    "\n",
    "\n",
    "for i in range(num_items):\n",
    "        item_i = list_items[i]\n",
    "        df_reviews_i = df_reviews[df_reviews[\"item_id\"] == item_i].head(number_reviews)\n",
    "        df_reviews_i_kendall = df_reviews[df_reviews[\"item_id\"] == item_i].head(number_kendall)\n",
    "\n",
    "        list_df_attr_i = []\n",
    "        list_df_attr_i_kendall = []\n",
    "        for j in range(num_attr):\n",
    "                list_df_attr_i.append(df_reviews_i[df_reviews_i[column_str] == list_attr[j]]) \n",
    "                list_df_attr_i_kendall.append(df_reviews_i_kendall[df_reviews_i_kendall[column_str] == list_attr[j]])\n",
    "\n",
    "\n",
    "\n",
    "        for j in range(num_attr):\n",
    "                if len(list_df_attr_i[j]) > 0:\n",
    "                        list_of_lists_items_exp_avg[i].append(exposure_avg(list_df_attr_i[j]))\n",
    "                        list_of_lists_items_exp_top[i].append(exposure_top(list_df_attr_i[j]))\n",
    "                        #list_of_lists_items_treatment_avg[i].append(treatment_avg(list_df_attr_i[j]))\n",
    "                        list_of_lists_items_treatment_top[i].append(treatment_top(list_df_attr_i[j]))\n",
    "                else:\n",
    "                        #print(\"HO UN CASO NULLO\", list_attr[j])\n",
    "                        list_of_lists_items_exp_avg[i].append(0)\n",
    "                        list_of_lists_items_exp_top[i].append(0)\n",
    "                        #list_of_lists_items_treatment_avg[i].append(0)\n",
    "                        list_of_lists_items_treatment_top[i].append(0)\n",
    "\n",
    "\n",
    "                if len(list_df_attr_i_kendall[j]) > 0:\n",
    "                        # PER LA KENDALL DEVO CALCOLARE IL DF DIFFERENCE\n",
    "                        merged_df = df_reviews_i_kendall.merge(list_df_attr_i_kendall[j], how='left', indicator=True)\n",
    "                        difference_df = merged_df[merged_df['_merge'] == 'left_only'].drop(columns='_merge')\n",
    "\n",
    "                        if (len(difference_df) != 0):\n",
    "                                list_of_lists_items_kendall[i].append(kendall_tau_asymmetric(list_df_attr_i_kendall[j], difference_df))\n",
    "                else:\n",
    "                        list_of_lists_items_kendall[i].append(-2)\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_boxplot/one_level/list_of_lists_items_exp_avg.txt', 'w') as file:\n",
    "    for sublist in list_of_lists_items_exp_avg:\n",
    "        file.write('[' + ', '.join(map(str, sublist)) + ']\\n')\n",
    "\n",
    "with open('data_boxplot/one_level/list_of_lists_items_exp_top.txt', 'w') as file:\n",
    "    for sublist in list_of_lists_items_exp_top:\n",
    "        file.write('[' + ', '.join(map(str, sublist)) + ']\\n')\n",
    "\n",
    "#with open('data_boxplot/one_level/list_of_lists_items_treatment_avg.txt', 'w') as file:\n",
    "#    for sublist in list_of_lists_items_treatment_avg:\n",
    "#        file.write('[' + ', '.join(map(str, sublist)) + ']\\n')\n",
    "\n",
    "with open('data_boxplot/one_level/list_of_lists_items_treatment_top.txt', 'w') as file:\n",
    "    for sublist in list_of_lists_items_treatment_top:\n",
    "        file.write('[' + ', '.join(map(str, sublist)) + ']\\n')\n",
    "\n",
    "with open('data_boxplot/one_level/list_of_lists_items_kendall.txt', 'w') as file:\n",
    "    for sublist in list_of_lists_items_kendall:\n",
    "        file.write('[' + ', '.join(map(str, sublist)) + ']\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dirpath = Path.cwd()/ 'data_boxplot/one_level'\n",
    "# list the text files in the data directory\n",
    "text_files = list(data_dirpath.glob('*.txt'))\n",
    "\n",
    "# iterate through the text files and parse the data\n",
    "fairness_measure_to_df = {}\n",
    "for filepath in text_files:\n",
    "    filename = filepath.stem\n",
    "    filename = filename.split('_')\n",
    "    fairness_measure_name = filename[-2:]\n",
    "    fairness_measure_name = '_'.join(fairness_measure_name)\n",
    "    fairness_measure_to_df[fairness_measure_name] = parse_into_dataframe(filepath)\n",
    "\n",
    "# replace every -2 with NaN for the item_kendall fairness measure and\n",
    "# every 0 with NaN for the other fairness measures\n",
    "for fairness_measure, df in fairness_measure_to_df.items():\n",
    "    if fairness_measure == 'items_kendall':\n",
    "        fairness_measure_to_df[fairness_measure] = df.replace(-2, pd.NA)\n",
    "    else:\n",
    "        fairness_measure_to_df[fairness_measure] = df.replace(0, pd.NA)\n",
    "\n",
    "# generate a boxplot for each fairness measure\n",
    "# and save the plot as an html file\n",
    "for fairness_measure, df in fairness_measure_to_df.items():\n",
    "\n",
    "    print(fairness_measure)\n",
    "    fig = go.Figure()\n",
    "    for column in df.columns:\n",
    "        fig.add_trace(go.Box(y=df[column], name=column))\n",
    "    \n",
    "    # set the y-axis range to be between 0 and 1 except for the item_kendall fairness measure\n",
    "    # where the range is between -1 and 1\n",
    "    if fairness_measure == 'items_kendall':\n",
    "        fig.update_layout(yaxis_range=[-1.1, 1.1])\n",
    "        #fig.update_layout(title = fairness_measure)\n",
    "    else:\n",
    "        fig.update_layout(yaxis_range=[-0.1, 1.1])\n",
    "        #fig.update_layout(title =  str(fairness_measure)+str(\" for \") + str(column_str) + str(\" with first \")+ str(number_reviews)+ \" reviews\")\n",
    "\n",
    "    \n",
    "    #fig.update_layout(showlegend=False,xaxis=dict(title='', showticklabels=False), width=300, height=250)\n",
    "    fig.update_layout(showlegend=False, width=300, height=250)\n",
    "\n",
    "    # Define the custom labels you want to use\n",
    "    fig.update_xaxes(tickvals=list_attr, ticktext=list_symbols)\n",
    "\n",
    "    #fig.update_layout(title = fairness_measure)\n",
    "\n",
    "    #if fairness_measure == 'items_kendall':\n",
    "    #    fig.update_layout(annotations=[dict(x=-0.12, y=0.5, text=\"rank_equality\", showarrow=False, textangle=-90, \n",
    "    #                      xref=\"paper\", yref=\"paper\", font=dict(size=14))])      \n",
    "    #else:\n",
    "    #    fig.update_layout(annotations=[dict(x=-0.12, y=0.5, text=fairness_measure, showarrow=False, textangle=-90, \n",
    "    #                      xref=\"paper\", yref=\"paper\", font=dict(size=14))])\n",
    "    fig.update_layout(margin=dict(l=5, r=5, t=5, b=0))\n",
    "    #fig.update_layout(showlegend=True)\n",
    "\n",
    "    #fig.update_layout(\n",
    "    #xaxis_title=['5','4','3','2','1']\n",
    "    #)\n",
    "    \n",
    "    fig.write_image(\"data_boxplot/plot/one_level/\"+str(fairness_measure)+\".png\")\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TWO LEVELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query1 = pd.read_csv(\"query_yelp/query1.csv\")\n",
    "df_query2 = pd.read_csv(\"query_yelp/query2.csv\")\n",
    "df_query3 = pd.read_csv(\"query_yelp/query3.csv\")\n",
    "df_query4 = pd.read_csv(\"query_yelp/query4.csv\")\n",
    "df_query5 = pd.read_csv(\"query_yelp/query5.csv\")\n",
    "df_query6 = pd.read_csv(\"query_yelp/query6.csv\")\n",
    "\n",
    "df_query1 = df_query1.drop(\"query_id\", axis=1)\n",
    "df_query2 = df_query2.drop(\"query_id\", axis=1)\n",
    "df_query3 = df_query3.drop(\"query_id\", axis=1)\n",
    "df_query4 = df_query4.drop(\"query_id\", axis=1)\n",
    "df_query5 = df_query5.drop(\"query_id\", axis=1)\n",
    "df_query6 = df_query6.drop(\"query_id\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(df_query[\"ordering_attributes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_query = df_query1 # OR\n",
    "#df_query = df_query2 # OR\n",
    "#df_query = df_query3 # OR\n",
    "df_query = df_query4 # OR\n",
    "#df_query = df_query5 # OR\n",
    "#df_query = df_query6 \n",
    "\n",
    "df_query[\"query_attributes\"] = df_query[\"query_attributes\"].apply(literal_eval)\n",
    "df_query[\"ordering_attributes\"] = df_query[\"ordering_attributes\"].apply(literal_eval)\n",
    "\n",
    "number_reviews_two_levels = 15\n",
    "\n",
    "# ADD TYPE FIELD\n",
    "df_query['type'] = None\n",
    "for index, row in df_query.iterrows():\n",
    "    #print(row[\"ordering_attributes\"])\n",
    "    if row[\"ordering_attributes\"]:\n",
    "        df_query.loc[index,'type'] = row[\"ordering_attributes\"][0]\n",
    "    else:\n",
    "        df_query.loc[index,'type'] = \"none\"\n",
    "\n",
    "print(set(df_query[\"type\"]))\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "# DELETE \"none\" and fix ordering_id\n",
    "df_query = df_query[df_query [\"type\"] != \"none\"]\n",
    "df_query[\"ordering_id\"] = df_query[\"ordering_id\"] -1\n",
    "\n",
    "k = len(df_query[df_query[\"ordering_id\"] == 2])\n",
    "p = max(df_query[\"ordering_id\"])\n",
    "print(\"numero di permutazioni, numero di ristoranti =\",p,\",\",k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(df_query[\"ordering_attributes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    # DELETE ALL ROWS SO THAT ['ordering_attributes'] IS LONGER THAN 1\n",
    "    df_query = df_query[df_query['ordering_attributes'].apply(lambda x: len(x) <= 1)]\n",
    "\n",
    "    # TRASFORM ROWS\n",
    "    df_query['ordering_direction'] = df_query['ordering_direction'].apply(lambda x: eval(x))\n",
    "    df_query['ordering_direction'] = df_query['ordering_direction'].apply(lambda x: x[0])\n",
    "\n",
    "    #print(df_query['ordering_attributes'])\n",
    "\n",
    "    #df_query['ordering_attributes'] = df_query['ordering_attributes'].apply(lambda x: eval(x))\n",
    "    df_query['ordering_attributes'] = df_query['ordering_attributes'].apply(lambda x: x[0])\n",
    "\n",
    "    df_query['string'] = df_query['ordering_attributes'] + ' ' + df_query['ordering_direction']\n",
    "    #df_query\n",
    "\n",
    "    # CHANGE SOME VALUES AND DELETE \"distance asc\"\n",
    "    df_query['string'] = df_query['string'].replace('attributes.RestaurantsPriceRange2 desc', 'price desc')\n",
    "    df_query['string'] = df_query['string'].replace('attributes.RestaurantsPriceRange2 asc', 'price asc')\n",
    "    df_query['string'] = df_query['string'].replace('review_count desc', '#reviews desc')\n",
    "    df_query = df_query[df_query['string'] != \"distance desc\"]\n",
    "    df_query.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "    number_singles = int(len(df_query)/k)\n",
    "    #display(sub_df)\n",
    "    repeated_numbers = [num for num in range(1, number_singles+1) for _ in range(k)]\n",
    "    print(repeated_numbers)\n",
    "    print(len(repeated_numbers), len(df_query))\n",
    "    df_query[\"ordering_id\"] = repeated_numbers\n",
    "\n",
    "    df_query.reset_index(inplace=True)\n",
    "\n",
    "    k = len(df_query[df_query[\"ordering_id\"] == 2])\n",
    "    p = max(df_query[\"ordering_id\"])\n",
    "    print(\"number of permutations, number of restaurant =\",p,\",\",k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe 2 levels\n",
    "if True:\n",
    "    exp_avg_2_levels = list() \n",
    "    exp_top_2_levels = list() \n",
    "    treatment_top_2_levels = list() \n",
    "    for j in range(p):\n",
    "            exp_avg_2_levels.append(list())\n",
    "            exp_top_2_levels.append(list())\n",
    "            treatment_top_2_levels.append(list())\n",
    "\n",
    "\n",
    "    for i in range(p):\n",
    "\n",
    "        permutation_items = df_query[df_query[\"ordering_id\"] == i+1][\"item_id\"].tolist()\n",
    "\n",
    "        list_of_lists_items_exp_avg = list()\n",
    "        list_of_lists_items_exp_top = list()\n",
    "        list_of_lists_items_treatment_top = list()\n",
    "        for j in range(k):\n",
    "                list_of_lists_items_exp_avg.append(list())\n",
    "                list_of_lists_items_exp_top.append(list())\n",
    "                list_of_lists_items_treatment_top.append(list())\n",
    "\n",
    "\n",
    "        for z in range(len(permutation_items)):\n",
    "            #print(\"z = \", z)\n",
    "\n",
    "            item = permutation_items[z]\n",
    "            df_i = df_reviews[df_reviews[\"item_id\"] == item].head(number_reviews_two_levels)\n",
    "\n",
    "            list_df_attr_i = []\n",
    "            for j in range(num_attr):\n",
    "                    list_df_attr_i.append(df_i[df_i[column_str] == list_attr[j]]) \n",
    "\n",
    "\n",
    "            for j in range(num_attr):\n",
    "                if len(list_df_attr_i[j]) > 0:\n",
    "                        list_of_lists_items_exp_avg[z].append(exposure_avg(list_df_attr_i[j]))\n",
    "                        list_of_lists_items_exp_top[z].append(exposure_top(list_df_attr_i[j]))\n",
    "                        list_of_lists_items_treatment_top[z].append(treatment_top(list_df_attr_i[j]))\n",
    "                else:\n",
    "                        list_of_lists_items_exp_avg[z].append(0)\n",
    "                        list_of_lists_items_exp_top[z].append(0)\n",
    "                        list_of_lists_items_treatment_top[z].append(0)\n",
    "\n",
    "        normalization_factor = 0\n",
    "        for w in range(k):\n",
    "                normalization_factor += (1/(math.log(w+2,2)))\n",
    "\n",
    "\n",
    "        for x in range(num_attr):\n",
    "            count = 0\n",
    "            for w in range(k):\n",
    "                count += (1/(math.log(w+2,2))) * list_of_lists_items_exp_avg[w][x]\n",
    "            exp_avg_2_levels[i].append(count/normalization_factor)\n",
    "\n",
    "        for x in range(num_attr):\n",
    "            count = 0\n",
    "            for w in range(k):\n",
    "                count += (1/(math.log(w+2,2))) * list_of_lists_items_exp_top[w][x]\n",
    "            exp_top_2_levels[i].append(count/normalization_factor)\n",
    "\n",
    "        for x in range(num_attr):\n",
    "            count = 0\n",
    "            for w in range(k):\n",
    "                count += (1/(math.log(w+2,2))) * list_of_lists_items_treatment_top[w][x]\n",
    "            treatment_top_2_levels[i].append(count/normalization_factor)  \n",
    "\n",
    "# Save the dataframes\n",
    "if True:\n",
    "    with open('data_boxplot/two_levels/list_of_lists_items_exp_avg.txt', 'w') as file:\n",
    "        for sublist in exp_avg_2_levels:\n",
    "            file.write('[' + ', '.join(map(str, sublist)) + ']\\n')\n",
    "\n",
    "    with open('data_boxplot/two_levels/list_of_lists_items_exp_top.txt', 'w') as file:\n",
    "        for sublist in exp_top_2_levels:\n",
    "            file.write('[' + ', '.join(map(str, sublist)) + ']\\n')\n",
    "\n",
    "    with open('data_boxplot/two_levels/list_of_lists_items_treatment_top.txt', 'w') as file:\n",
    "        for sublist in treatment_top_2_levels:\n",
    "            file.write('[' + ', '.join(map(str, sublist)) + ']\\n')\n",
    "\n",
    "# Create the fairness_measures\n",
    "if True:\n",
    "    data_dirpath = Path.cwd()/ 'data_boxplot/two_levels'\n",
    "    # list the text files in the data directory\n",
    "    text_files = list(data_dirpath.glob('*.txt'))\n",
    "\n",
    "    # iterate through the text files and parse the data\n",
    "    fairness_measure_to_df = {}\n",
    "    for filepath in text_files:\n",
    "        filename = filepath.stem\n",
    "        filename = filename.split('_')\n",
    "        fairness_measure_name = filename[-2:]\n",
    "        fairness_measure_name = '_'.join(fairness_measure_name)\n",
    "        fairness_measure_to_df[fairness_measure_name] = parse_into_dataframe(filepath)\n",
    "\n",
    "    # replace every -2 with NaN for the item_kendall fairness measure and\n",
    "    # every 0 with NaN for the other fairness measures\n",
    "    for fairness_measure, df in fairness_measure_to_df.items():\n",
    "        if fairness_measure == 'items_kendall':\n",
    "            fairness_measure_to_df[fairness_measure] = df.replace(-2, pd.NA)\n",
    "        else:\n",
    "            fairness_measure_to_df[fairness_measure] = df.replace(0, pd.NA)\n",
    "\n",
    "    # generate a boxplot for each fairness measure\n",
    "    # and save the plot as an html file\n",
    "\n",
    "    # TO PLOT THE BOXPLOT SET AS TRUE\n",
    "\n",
    "    if False:\n",
    "        for fairness_measure, df in fairness_measure_to_df.items():\n",
    "\n",
    "            print(fairness_measure)\n",
    "            fig = go.Figure()\n",
    "            for column in df.columns:\n",
    "                fig.add_trace(go.Box(y=df[column], name=column))\n",
    "            \n",
    "            # set the y-axis range to be between 0 and 1 except for the item_kendall fairness measure\n",
    "            # where the range is between -1 and 1\n",
    "            if fairness_measure == 'items_kendall':\n",
    "            #    fig.update_layout(yaxis_range=[-1, 1], title = fairness_measure)\n",
    "                fig.update_layout(yaxis_range=[-1, 1])\n",
    "            #if fairness_measure != 'exp_top':\n",
    "            #    fig.update_layout(yaxis_range=[0, 1], title = str(fairness_measure)+str(\" con \")+str(k)+\" ristoranti e \"+ str(number_reviews)+ \" a ristorante\")\n",
    "                \n",
    "            else:\n",
    "                #fig.update_layout(yaxis_range=[0, 1], title = str(fairness_measure)+str(\" con \")+str(k)+\" ristoranti e \"+ str(number_reviews)+ \" a ristorante\")\n",
    "                fig.update_layout(yaxis_range=[0, 1])\n",
    "\n",
    "\n",
    "            fig.update_layout(showlegend=False,xaxis=dict(title='', showticklabels=False), width=300, height=250)\n",
    "            fig.update_layout(margin=dict(l=5, r=5, t=5, b=0))\n",
    "\n",
    "            fig.write_image(\"data_SCATOLE_E_BAFFI/plot/two_levels/\"+str(fairness_measure)+\"_two_levels\"+\".png\")\n",
    "            #fig.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(2, 1)\n",
    "#plt.subplots_adjust(left=0.1, right=0.9, bottom=0.1, top=0.9, wspace=0.4, hspace=0.4)\n",
    "for measure in [\"exp_top\", \"treatment_top\"]:\n",
    "#for measure in [\"exp_top\"]:\n",
    "    df = fairness_measure_to_df[measure]\n",
    "\n",
    "    sublist = (list(df_query[\"string\"]))[::k]\n",
    "    df['color'] = sublist\n",
    "\n",
    "    column_names_map = dict(zip(list_attr, list_symbols))\n",
    "    # Rename columns\n",
    "    df = df.rename(columns=column_names_map)\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.tight_layout()\n",
    "    #plt.update_layout(margin=dict(l=5, r=5, t=5, b=0))\n",
    "\n",
    "    pd.plotting.parallel_coordinates(df, 'color', color=(\"#000000\",\"#009292\",\"#ff6db6\",\"#b6dbff\", \"#920000\",\"#db6d00\",\"#24ff24\",\"#ffff6d\"))\n",
    "    plt.savefig('data_boxplot/two_levels/'+measure+'.pdf', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with 1 row and 2 columns\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "#fig, ax = plt.subplots(2, 1)\n",
    "#plt.subplots_adjust(left=0.1, right=0.9, bottom=0.1, top=0.9, wspace=0.4, hspace=0.4)\n",
    "for (measure, ax) in zip([\"exp_top\", \"treatment_top\"], [ax1, ax2]):\n",
    "#for measure in [\"exp_top\"]:\n",
    "    df = fairness_measure_to_df[measure]\n",
    "\n",
    "    sublist = (list(df_query[\"string\"]))[::k]\n",
    "    df['color'] = sublist\n",
    "\n",
    "    column_names_map = dict(zip(list_attr, list_symbols))\n",
    "    # Rename columns\n",
    "    df = df.rename(columns=column_names_map)\n",
    "    df = df.dropna(axis=1, how='all')\n",
    "\n",
    "    \n",
    "    #plt.update_layout(margin=dict(l=5, r=5, t=5, b=0))\n",
    "\n",
    "    pd.plotting.parallel_coordinates(frame=df, ax=ax, class_column='color', color=(\"#000000\",\"#009292\",\"#ff6db6\",\"#b6dbff\", \"#920000\",\"#db6d00\",\"#24ff24\",\"#ffff6d\"))\n",
    "    #plt.savefig('data_boxplot/two_levels/'+measure+'.png', bbox_inches='tight')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('data_boxplot/two_levels/exp_treatment_top_subplot.pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fairness_measure_to_df[\"treatment_top\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
